import streamlit as st
import pandas as pd
import numpy as np
import random
import plotly.graph_objects as go
import colorsys



# åˆå§‹åŒ–session_state
if 'flow_df' not in st.session_state:
    st.session_state.flow_df = None
if 'source_nodes' not in st.session_state:
    st.session_state.source_nodes = []
if 'target_nodes' not in st.session_state:
    st.session_state.target_nodes = []
if 'selected_sources' not in st.session_state:
    st.session_state.selected_sources = []
if 'selected_targets' not in st.session_state:
    st.session_state.selected_targets = []
if 'start_period' not in st.session_state:
    st.session_state.start_period = None
if 'end_period' not in st.session_state:
    st.session_state.end_period = None
if 'highlight_keyword' not in st.session_state:
    st.session_state.highlight_keyword = "å®¶ä¹"
if 'show_rank_value' not in st.session_state:
    st.session_state.show_rank_value = True

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å“ç‰Œæµé‡æ¡‘åŸºå›¾åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"  # ä½¿ç”¨å®½å¸ƒå±€å¢åŠ ç©ºé—´
)


# æ ‡é¢˜
st.title("å“ç‰Œæµé‡æ¡‘åŸºå›¾åˆ†æå·¥å…·")

# å‚æ•°è®¾ç½®åŒºåŸŸ
st.subheader("åˆ†æå‚æ•°è®¾ç½®")
param_col1, param_col2 = st.columns(2)

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
with param_col1:
    uploaded_file = st.file_uploader("è¯·ä¸Šä¼ Excelæ ¼å¼çš„æ•°æ®æ–‡ä»¶ï¼ˆ.xlsxï¼‰", type=["xlsx"])

# å¦‚æœä¸Šä¼ äº†æ–‡ä»¶ï¼Œåˆ™è¿›è¡Œåç»­å‚æ•°è®¾ç½®
if uploaded_file is not None:
    # è¯»å–æ•°æ®ä»¥è·å–Qçš„å¯èƒ½å€¼
    df = pd.read_excel(uploaded_file)
    if 'Q' not in df.columns:
        st.error("ä¸Šä¼ çš„æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„'Q'åˆ—")
        st.stop()
    
    # è·å–Qçš„å”¯ä¸€å€¼å¹¶æ’åº
    q_values = sorted(df['Q'].unique().tolist())
    
    with param_col1:
        # æœŸåˆå’ŒæœŸæœ«é€‰æ‹©
        col1, col2 = st.columns(2)
        with col1:
            start_period = st.selectbox("é€‰æ‹©æœŸåˆ", q_values, index=0)
            st.session_state.start_period = start_period
        with col2:
            end_period = st.selectbox("é€‰æ‹©æœŸæœ«", q_values, index=min(1, len(q_values)-1))
            st.session_state.end_period = end_period
        
        # ç¡®ä¿æœŸåˆä¸ç­‰äºæœŸæœ«
        if start_period == end_period:
            st.error("æœŸåˆå’ŒæœŸæœ«ä¸èƒ½é€‰æ‹©ç›¸åŒçš„å€¼ï¼Œè¯·é‡æ–°é€‰æ‹©")
            st.stop()
    
    with param_col2:
        # å…¶ä»–å‚æ•°è®¾ç½®
        highlight_keyword = st.text_input("èŠ‚ç‚¹é«˜äº®å…³é”®è¯", "å®¶ä¹")
        st.session_state.highlight_keyword = highlight_keyword
        
        top_n_brands = st.slider("ä¿ç•™Top Nå“ç‰Œæ•°é‡", 5, 20, 10)
        
        show_rank_value = st.checkbox("åœ¨èŠ‚ç‚¹æ ‡ç­¾ä¸­æ˜¾ç¤ºæ’åå’Œæ•°å€¼", value=True)
        st.session_state.show_rank_value = show_rank_value
        
        # ç”Ÿæˆæ¡‘åŸºå›¾æŒ‰é’®
        generate_chart = st.button("ç”Ÿæˆæ¡‘åŸºå›¾")
    
    # å½“ç‚¹å‡»ç”ŸæˆæŒ‰é’®æ—¶è¿›è¡Œå¤„ç†
    if generate_chart:
        with st.spinner("æ­£åœ¨è¯»å–å’Œå¤„ç†æ•°æ®..."):
            # ç»Ÿä¸€Value Uåˆ—å
            if 'Value U' not in df.columns and 'Value' in df.columns:
                df = df.rename(columns={'Value': 'Value U'})
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['brand', 'Value U', 'Passport_id', 'Q']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                st.error(f"ä¸Šä¼ çš„æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_columns)}")
                st.stop()
            
            # å¤„ç†å“ç‰Œåˆ—ï¼šèšåˆValue Uå¹¶ä¿ç•™Top Nå“ç‰Œï¼Œç»Ÿä¸€å“ç‰Œåç§°æ ¼å¼
            df['brand_clean'] = df['brand'].str.strip().str.lower()  # æ¸…æ´—å“ç‰Œåç§°
            brand_values = df.groupby('brand_clean')['Value U'].sum().reset_index()
            brand_values_sorted = brand_values.sort_values('Value U', ascending=False)
            top_brands = brand_values_sorted.head(top_n_brands)['brand_clean'].tolist()
            df['brand_processed'] = df['brand_clean'].apply(lambda x: x if x in top_brands else 'å…¶ä»–å“ç‰Œ')
            
            st.success(f"å·²å¤„ç†å“ç‰Œåˆ—ï¼Œä¿ç•™Top {top_n_brands}å“ç‰Œï¼Œå…¶ä½™å½’ä¸º'å…¶ä»–å“ç‰Œ'")
        
        # è®¡ç®—æµå‘æ•°æ®
        with st.spinner("æ­£åœ¨è®¡ç®—æµå‘æ•°æ®..."):
            flow_results = []
            
            # æŒ‰Passport_idåˆ†ç»„å¤„ç†
            for passport_id, group in df.groupby('Passport_id'):
                # æ£€æŸ¥æ˜¯å¦æœ‰æœŸåˆå’ŒæœŸæœ«æ•°æ®
                has_start = start_period in group['Q'].values
                has_end = end_period in group['Q'].values
                
                # åœºæ™¯1ï¼šåªæœ‰æœŸæœ«ï¼ˆæœŸæœ«æœ‰å€¼ï¼ŒæœŸåˆæ— å€¼ï¼‰
                if not has_start and has_end:
                    # æ‰€æœ‰å“ç‰Œéƒ½æ¥è‡ªæœŸåˆ_æ–°å¢é—¨åº—
                    brand_data = group[group['Q'] == end_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    for _, row in brand_data.iterrows():
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_æ–°å¢é—¨åº—",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{row['brand_processed']}",
                            'æµé‡': row['Value U']
                        })
                    continue
                
                # åœºæ™¯2ï¼šåªæœ‰æœŸåˆï¼ˆæœŸåˆæœ‰å€¼ï¼ŒæœŸæœ«æ— å€¼ï¼‰
                if has_start and not has_end:
                    # æ‰€æœ‰å“ç‰Œæµå‘æœŸæœ«_é—¨åº—æµå¤±
                    brand_data = group[group['Q'] == start_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    for _, row in brand_data.iterrows():
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{row['brand_processed']}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_é—¨åº—æµå¤±",
                            'æµé‡': row['Value U']
                        })
                    continue
                
                # åœºæ™¯3ï¼šæ—¢æœ‰æœŸåˆåˆæœ‰æœŸæœ«ï¼ˆå¤„ç†å®Œæ•´æµå‘ï¼‰
                if has_start and has_end:
                    # æŒ‰å“ç‰ŒèšåˆæœŸåˆå’ŒæœŸæœ«çš„æ•°æ®
                    start_data = group[group['Q'] == start_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    end_data = group[group['Q'] == end_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    
                    start_dict = dict(zip(start_data['brand_processed'], start_data['Value U']))
                    end_dict = dict(zip(end_data['brand_processed'], end_data['Value U']))
                    
                    # 1. ç›¸åŒå“ç‰Œä¼˜å…ˆåŒ¹é…
                    common_brands = set(start_dict.keys()) & set(end_dict.keys())
                    remaining_start = start_dict.copy()
                    remaining_end = end_dict.copy()
                    
                    for brand in common_brands:
                        flow = min(start_dict[brand], end_dict[brand])
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand}",
                            'æµé‡': flow
                        })
                        # æ›´æ–°å‰©ä½™é‡
                        remaining_start[brand] -= flow
                        remaining_end[brand] -= flow
                        if remaining_start[brand] == 0:
                            del remaining_start[brand]
                        if remaining_end[brand] == 0:
                            del remaining_end[brand]
                    
                    # 2. ä¸åŒå“ç‰ŒéšæœºåŒ¹é…å‰©ä½™é‡
                    start_remaining = list(remaining_start.items())
                    end_remaining = list(remaining_end.items())
                    
                    while start_remaining and end_remaining:
                        brand1, val1 = start_remaining[0]
                        brand2, val2 = random.choice(end_remaining)
                        
                        flow = min(val1, val2)
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand1}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand2}",
                            'æµé‡': flow
                        })
                        
                        # æ›´æ–°å‰©ä½™é‡
                        if val1 == flow:
                            start_remaining.pop(0)
                        else:
                            start_remaining[0] = (brand1, val1 - flow)
                            
                        idx = end_remaining.index((brand2, val2))
                        if val2 == flow:
                            end_remaining.pop(idx)
                        else:
                            end_remaining[idx] = (brand2, val2 - flow)
                    
                    # 3. å¤„ç†æœ€ç»ˆä½™é‡
                    # æœŸåˆå‰©ä½™é‡æµå‘æœŸæœ«_å“ç±»æµå¤±
                    for brand, value in start_remaining:
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_å“ç±»æµå¤±",
                            'æµé‡': value
                        })
                    
                    # æœŸæœ«å‰©ä½™é‡æ¥è‡ªæœŸåˆ_æ–°å¢å“ç±»
                    for brand, value in end_remaining:
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_æ–°å¢å“ç±»",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand}",
                            'æµé‡': value
                        })
            
            # ç¡®ä¿flow_dfåŒ…å«æ­£ç¡®çš„åˆ—å
            st.session_state.flow_df = pd.DataFrame(flow_results, columns=['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹', 'æµé‡'])
            st.success("æµå‘æ•°æ®è®¡ç®—å®Œæˆ")
            
            # ä¿å­˜èŠ‚ç‚¹ä¿¡æ¯
            st.session_state.source_nodes = st.session_state.flow_df['èµ·å§‹ç‚¹'].unique().tolist()
            st.session_state.target_nodes = st.session_state.flow_df['ç›®æ ‡ç‚¹'].unique().tolist()
            
            # åˆå§‹åŒ–é€‰æ‹©
            st.session_state.selected_sources = st.session_state.source_nodes
            st.session_state.selected_targets = st.session_state.target_nodes
    
    # åªæœ‰å½“æœ‰æ•°æ®æ—¶æ‰æ˜¾ç¤ºç­›é€‰å’Œå›¾è¡¨
    if st.session_state.flow_df is not None and not st.session_state.flow_df.empty:
        # éªŒè¯å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_flow_columns = ['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹', 'æµé‡']
        missing_flow_cols = [col for col in required_flow_columns if col not in st.session_state.flow_df.columns]
        if missing_flow_cols:
            st.error(f"æµå‘æ•°æ®ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_flow_cols)}")
            st.stop()
        
        # æ·»åŠ èŠ‚ç‚¹ç­›é€‰åŒºåŸŸ
        st.subheader("èŠ‚ç‚¹ç­›é€‰")
        filter_col1, filter_col2 = st.columns(2)
        with filter_col1:
            selected_sources = st.multiselect(
                "é€‰æ‹©è¦æ˜¾ç¤ºçš„æœŸåˆèŠ‚ç‚¹",
                st.session_state.source_nodes,
                default=st.session_state.selected_sources
            )
            st.session_state.selected_sources = selected_sources
        with filter_col2:
            selected_targets = st.multiselect(
                "é€‰æ‹©è¦æ˜¾ç¤ºçš„æœŸæœ«èŠ‚ç‚¹",
                st.session_state.target_nodes,
                default=st.session_state.selected_targets
            )
            st.session_state.selected_targets = selected_targets
        
        # åº”ç”¨ç­›é€‰
        filtered_flow_df = st.session_state.flow_df[
            st.session_state.flow_df['èµ·å§‹ç‚¹'].isin(st.session_state.selected_sources) & 
            st.session_state.flow_df['ç›®æ ‡ç‚¹'].isin(st.session_state.selected_targets)
        ]
        
        # å¦‚æœç­›é€‰åæ²¡æœ‰æ•°æ®
        if filtered_flow_df.empty:
            st.warning("ç­›é€‰åæ²¡æœ‰æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
        else:
            # ç”Ÿæˆæ¡‘åŸºå›¾ï¼ˆåŸºäºç­›é€‰åçš„æ•°æ®ï¼‰
            with st.spinner("æ­£åœ¨ç”Ÿæˆæ¡‘åŸºå›¾..."):
                # ç¡®ä¿èšåˆæ—¶ä½¿ç”¨æ­£ç¡®çš„åˆ—å
                aggregated_df = filtered_flow_df.groupby(['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹'], as_index=False)['æµé‡'].sum()
                
                # åˆ†ç¦»æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹
                source_nodes_unique = aggregated_df['èµ·å§‹ç‚¹'].unique().tolist()
                target_nodes_unique = aggregated_df['ç›®æ ‡ç‚¹'].unique().tolist()
                
                # åˆ†åˆ«æŒ‰æµé‡æ’åº
                # æºèŠ‚ç‚¹æŒ‰æµå‡ºæµé‡æ’åºï¼ˆé™åºï¼‰
                source_flow = aggregated_df.groupby('èµ·å§‹ç‚¹')['æµé‡'].sum().reset_index()
                source_flow.columns = ['èŠ‚ç‚¹', 'æ€»æµé‡']
                source_flow_sorted = source_flow.sort_values('æ€»æµé‡', ascending=False).reset_index(drop=True)
                sorted_source_nodes = source_flow_sorted['èŠ‚ç‚¹'].tolist()
                
                # ç›®æ ‡èŠ‚ç‚¹æŒ‰æµå…¥æµé‡æ’åºï¼ˆé™åºï¼‰
                target_flow = aggregated_df.groupby('ç›®æ ‡ç‚¹')['æµé‡'].sum().reset_index()
                target_flow.columns = ['èŠ‚ç‚¹', 'æ€»æµé‡']
                target_flow_sorted = target_flow.sort_values('æ€»æµé‡', ascending=False).reset_index(drop=True)
                sorted_target_nodes = target_flow_sorted['èŠ‚ç‚¹'].tolist()
                
                # åˆå¹¶èŠ‚ç‚¹åˆ—è¡¨ï¼ˆå·¦ä¾§æºèŠ‚ç‚¹ + å³ä¾§ç›®æ ‡èŠ‚ç‚¹ï¼‰
                all_nodes = sorted_source_nodes + sorted_target_nodes
                
                # åˆ›å»ºèŠ‚ç‚¹ç´¢å¼•æ˜ å°„
                node_indices = {node: idx for idx, node in enumerate(all_nodes)}
                
                # å‡†å¤‡é“¾æ¥æ•°æ®
                links = {
                    'source': [node_indices[src] for src in aggregated_df['èµ·å§‹ç‚¹']],
                    'target': [node_indices[tar] for tar in aggregated_df['ç›®æ ‡ç‚¹']],
                    'value': aggregated_df['æµé‡'].tolist()
                }
                
                # é«˜äº®æŒ‡å®šå…³é”®è¯çš„èŠ‚ç‚¹
                highlight_nodes = [node for node in all_nodes if st.session_state.highlight_keyword in str(node).lower()]
                
                # ç”Ÿæˆæ¸…æ™°çš„è“è‰²ç³»é¢œè‰²å˜åŒ– - ä¸ä½¿ç”¨èƒŒæ™¯è‰²
                def generate_clear_blue_variations(n):
                    clear_blues = []
                    for i in range(n):
                        hue = 0.58  # è“è‰²è‰²ç›¸
                        saturation = 0.3 + (i % 3) * 0.1  # é€‚ä¸­é¥±å’Œåº¦
                        value = 0.9 + (i % 5) * 0.03  # é«˜æ˜åº¦
                        r, g, b = colorsys.hsv_to_rgb(hue, saturation, value)
                        clear_blues.append(f"rgb({int(r*255)}, {int(g*255)}, {int(b*255)})")  # ä¸é€æ˜
                    return clear_blues
                
                # ç”Ÿæˆæ¸…æ™°çš„è“è‰²ç³»é¢œè‰²
                highlight_colors = generate_clear_blue_variations(len(highlight_nodes))
                node_color_map = {node: color for node, color in zip(highlight_nodes, highlight_colors)}
                
                # èŠ‚ç‚¹é¢œè‰²è®¾ç½®ï¼šä½¿ç”¨ä¸é€æ˜è‰²ï¼Œæ— èƒŒæ™¯å½±å“
                node_colors = []
                base_clear_blue = "rgb(220, 235, 255)"  # åŸºç¡€æµ…è“è‰²ï¼ˆä¸é€æ˜ï¼‰
                
                for node in all_nodes:
                    if node in node_color_map:
                        node_colors.append(node_color_map[node])
                    else:
                        node_colors.append(base_clear_blue)
                
                # é“¾æ¥é¢œè‰²è®¾ç½®ï¼šé™ä½é€æ˜åº¦ä»¥å‡å°‘é‡å½±å½±å“
                link_colors = []
                for src, tar in zip(aggregated_df['èµ·å§‹ç‚¹'], aggregated_df['ç›®æ ‡ç‚¹']):
                    if src in node_color_map:
                        # ä½¿ç”¨æºèŠ‚ç‚¹é¢œè‰²ï¼Œé™ä½é€æ˜åº¦
                        link_colors.append(node_color_map[src].replace("rgb", "rgba").replace(")", ", 0.5)"))
                    elif tar in node_color_map:
                        # ä½¿ç”¨ç›®æ ‡èŠ‚ç‚¹é¢œè‰²ï¼Œé™ä½é€æ˜åº¦
                        link_colors.append(node_color_map[tar].replace("rgb", "rgba").replace(")", ", 0.5)"))
                    else:
                        # éé«˜äº®èŠ‚ç‚¹çš„é“¾æ¥ä½¿ç”¨æµ…è“è‰²
                        link_colors.append("rgba(220, 235, 255, 0.5)")
                
                # ä¼˜åŒ–èŠ‚ç‚¹ä½ç½®è®¡ç®—ï¼Œé¿å…é‡å 
                source_count = len(sorted_source_nodes)
                target_count = len(sorted_target_nodes)
                total_nodes = len(all_nodes)
                
                # åŠ¨æ€è°ƒæ•´èŠ‚ç‚¹é—´è·ï¼ŒèŠ‚ç‚¹è¶Šå¤šé—´è·è¶Šå¤§
                min_spacing = 0.08  # å¢å¤§æœ€å°é—´è·ï¼Œå‡å°‘é‡å 
                source_spacing = max(0.8 / max(source_count - 1, 1), min_spacing) if source_count > 1 else 0
                target_spacing = max(0.8 / max(target_count - 1, 1), min_spacing) if target_count > 1 else 0
                
                # æ°´å¹³ä½ç½®æ§åˆ¶ï¼ˆæºèŠ‚ç‚¹åœ¨å·¦ï¼Œç›®æ ‡èŠ‚ç‚¹åœ¨å³ï¼Œå¢åŠ é—´è·ï¼‰
                node_x = [0.15 for _ in range(source_count)] + [0.85 for _ in range(target_count)]
                
                # å‚ç›´ä½ç½®æ§åˆ¶ï¼ˆæ›´å‡åŒ€çš„åˆ†å¸ƒç®—æ³•ï¼‰
                node_y = []
                # æºèŠ‚ç‚¹å‚ç›´åˆ†å¸ƒ
                for i in range(source_count):
                    if source_count == 1:
                        node_y.append(0.5)  # å•ä¸ªèŠ‚ç‚¹å±…ä¸­
                    else:
                        node_y.append(0.1 + i * source_spacing)
                
                # ç›®æ ‡èŠ‚ç‚¹å‚ç›´åˆ†å¸ƒ
                for i in range(target_count):
                    if target_count == 1:
                        node_y.append(0.5)  # å•ä¸ªèŠ‚ç‚¹å±…ä¸­
                    else:
                        node_y.append(0.1 + i * target_spacing)
                
                # åŠ¨æ€è°ƒæ•´å­—ä½“å¤§å°ï¼Œé¿å…æ–‡å­—æ‹¥æŒ¤
                base_font_size = 12
                font_size = max(8, base_font_size - (total_nodes // 10))  # èŠ‚ç‚¹è¶Šå¤šå­—ä½“è¶Šå°
                
                # èŠ‚ç‚¹æ ‡ç­¾ï¼ˆç²¾ç®€æ ‡ç­¾å†…å®¹ï¼Œé¿å…è¿‡é•¿ï¼‰
                node_labels = []
                # æºèŠ‚ç‚¹æ ‡ç­¾ï¼ˆè½¬æ¢ä¸ºä¸‡å•ä½ï¼‰
                for i, node in enumerate(sorted_source_nodes):
                    flow = source_flow_sorted[source_flow_sorted['èŠ‚ç‚¹'] == node]['æ€»æµé‡'].values[0] / 10000
                    if st.session_state.show_rank_value:
                        # ç²¾ç®€æ ‡ç­¾ï¼Œåªä¿ç•™å…³é”®ä¿¡æ¯
                        node_name = node.replace("æœŸåˆ_", "")
                        node_labels.append(f"S{i+1}. {node_name} ({flow:.1f}ä¸‡)")
                    else:
                        node_labels.append(f"{node.replace('æœŸåˆ_', '')}")
                
                # ç›®æ ‡èŠ‚ç‚¹æ ‡ç­¾
                for i, node in enumerate(sorted_target_nodes):
                    flow = target_flow_sorted[target_flow_sorted['èŠ‚ç‚¹'] == node]['æ€»æµé‡'].values[0] / 10000
                    if st.session_state.show_rank_value:
                        node_name = node.replace("æœŸæœ«_", "")
                        node_labels.append(f"T{i+1}. {node_name} ({flow:.1f}ä¸‡)")
                    else:
                        node_labels.append(f"{node.replace('æœŸæœ«_', '')}")
                
                # ç»˜åˆ¶æ¡‘åŸºå›¾ï¼Œä¼˜åŒ–èŠ‚ç‚¹æ ·å¼ï¼Œè§£å†³é‡å½±é—®é¢˜
                fig = go.Figure(data=[go.Sankey(
                    arrangement="perpendicular",  # ä½¿ç”¨æ›´ç¨³å®šçš„å¸ƒå±€ç®—æ³•
                    node=dict(
                        pad=40,  # å¢å¤§èŠ‚ç‚¹é—´è·ï¼Œå‡å°‘é‡å 
                        thickness=30,  # é€‚å½“å‡å°åšåº¦
                        line=dict(color="rgba(100, 150, 255, 0.3)", width=1),  # è½»å¾®è¾¹æ¡†åŒºåˆ†èŠ‚ç‚¹
                        label=node_labels,
                        color=node_colors,
                        x=node_x,
                        y=node_y
                    ),
                    link=dict(
                        source=links['source'],
                        target=links['target'],
                        value=links['value'],
                        color=link_colors,
                        line=dict(width=0)  # ç§»é™¤é“¾æ¥è¾¹æ¡†ï¼Œå‡å°‘é‡å½±
                    )
                )])
                
                # ä¼˜åŒ–å¸ƒå±€å’Œå­—ä½“æ¸²æŸ“ - é€‚é…Streamlit Cloudç¯å¢ƒ
                fig.update_layout(
                    title_text=f"å“ç‰Œæµé‡æ¡‘åŸºå›¾ï¼ˆ{start_period} â†’ {end_period}ï¼‰- ç­›é€‰å",
                    font=dict(
                        family="Microsoft YaHei, SimHei, sans-serif",  # å¢åŠ å¤‡é€‰å­—ä½“
                        size=font_size,
                        color="rgb(30, 30, 30)"  # æ·±ç°è‰²æ–‡å­—æé«˜æ¸…æ™°åº¦
                    ),
                    # ç§»é™¤å›ºå®šå®½åº¦ï¼Œä½¿ç”¨è‡ªé€‚åº”
                    height=max(source_count, target_count) * 60 + 200,  # å¢å¤§é«˜åº¦ç³»æ•°
                    margin=dict(l=80, r=80, t=80, b=80),  # ä¼˜åŒ–è¾¹è·
                    paper_bgcolor="rgba(0,0,0,0)",  # å®Œå…¨é€æ˜èƒŒæ™¯
                    plot_bgcolor="rgba(0,0,0,0)"    # å›¾è¡¨åŒºåŸŸé€æ˜
                )
                
                st.success("æ¡‘åŸºå›¾ç”Ÿæˆå®Œæˆ")
            
            # æ˜¾ç¤ºæ¡‘åŸºå›¾
            st.subheader(f"å“ç‰Œæµé‡æ¡‘åŸºå›¾ï¼ˆ{st.session_state.start_period} â†’ {st.session_state.end_period}ï¼‰")
            st.plotly_chart(fig, use_container_width=True)  # å¼ºåˆ¶è‡ªé€‚åº”å®¹å™¨
            
            # è®¡ç®—å¹¶æ˜¾ç¤ºæµé‡å æ¯”æ•°æ®ï¼ˆåŸºäºç­›é€‰åçš„æ•°æ®ï¼‰
            with st.spinner("æ­£åœ¨è®¡ç®—æµé‡å æ¯”æ•°æ®..."):
                # åˆ›å»ºå­—å…¸ç”¨äºå¿«é€ŸæŸ¥æ‰¾æ¯ä¸ªæºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹çš„æ€»æµé‡
                source_total_flow = dict(zip(source_flow['èŠ‚ç‚¹'], source_flow['æ€»æµé‡']))
                target_total_flow = dict(zip(target_flow['èŠ‚ç‚¹'], target_flow['æ€»æµé‡']))
                
                # æŒ‰æºèŠ‚ç‚¹åˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªç›®æ ‡èŠ‚ç‚¹çš„æµé‡å æ¯”
                result = []
                
                # éå†æ¯ä¸ªæºèŠ‚ç‚¹
                for source in sorted_source_nodes:
                    # ç­›é€‰å‡ºè¯¥æºèŠ‚ç‚¹çš„æ‰€æœ‰æµå‡ºæ•°æ®
                    source_data = aggregated_df[aggregated_df['èµ·å§‹ç‚¹'] == source]
                    
                    # è®¡ç®—æ€»æµé‡
                    total_source = source_total_flow[source]
                    
                    # å­˜å‚¨è¯¥æºèŠ‚ç‚¹çš„æ‰€æœ‰æµå‘ä¿¡æ¯
                    flow_info = {
                        'æºèŠ‚ç‚¹': source,
                        'æºèŠ‚ç‚¹æ€»æµé‡': total_source / 10000,  # è½¬æ¢ä¸ºä¸‡å•ä½
                        'æµå‘åˆ†å¸ƒ': []
                    }
                    
                    # éå†æ¯ä¸ªç›®æ ‡èŠ‚ç‚¹ï¼Œè®¡ç®—å æ¯”
                    for _, row in source_data.iterrows():
                        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åˆ—å
                        target = row['ç›®æ ‡ç‚¹']
                        flow = row['æµé‡']
                        total_target = target_total_flow[target]
                        
                        # è®¡ç®—å æ¯”ï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
                        pct_source = round((flow / total_source) * 100, 2)  # å æœŸåˆæ¯”
                        pct_target = round((flow / total_target) * 100, 2)  # å æœŸæœ«æ¯”
                        
                        flow_info['æµå‘åˆ†å¸ƒ'].append({
                            'ç›®æ ‡èŠ‚ç‚¹': target,
                            'æµé‡': flow / 10000,  # è½¬æ¢ä¸ºä¸‡å•ä½
                            'å æœŸåˆæ¯”(%)': pct_source,
                            'å æœŸæœ«æ¯”(%)': pct_target
                        })
                    
                    # æŒ‰å æ¯”é™åºæ’åº
                    flow_info['æµå‘åˆ†å¸ƒ'].sort(key=lambda x: x['å æœŸåˆæ¯”(%)'], reverse=True)
                    result.append(flow_info)
                
                # è½¬æ¢ä¸ºDataFrameä»¥ä¾¿æ›´å¥½åœ°æŸ¥çœ‹
                rows = []
                for item in result:
                    for flow in item['æµå‘åˆ†å¸ƒ']:
                        rows.append({
                            'æºèŠ‚ç‚¹': item['æºèŠ‚ç‚¹'],
                            'æºèŠ‚ç‚¹æ€»æµé‡(ä¸‡)': item['æºèŠ‚ç‚¹æ€»æµé‡'],
                            'ç›®æ ‡èŠ‚ç‚¹': flow['ç›®æ ‡èŠ‚ç‚¹'],
                            'æµé‡(ä¸‡)': flow['æµé‡'],
                            'å æœŸåˆæ¯”(%)': flow['å æœŸåˆæ¯”(%)'],
                            'å æœŸæœ«æ¯”(%)': flow['å æœŸæœ«æ¯”(%)']
                        })
                
                percentage_df = pd.DataFrame(rows)
                st.success("æµé‡å æ¯”æ•°æ®è®¡ç®—å®Œæˆ")
            
            # æ˜¾ç¤ºæµé‡å æ¯”æ•°æ®ï¼ˆä¸»è¦è¾“å‡ºï¼‰
            st.subheader("æµé‡å æ¯”è¯¦ç»†æ•°æ®ï¼ˆç­›é€‰åï¼‰")
            st.dataframe(percentage_df)
            
            # ç”Ÿæˆå“ç‰Œåˆ†ææŠ¥å‘Š
            st.subheader("å“ç‰Œæµé‡åˆ†ææŠ¥å‘Š")
            
            # æå–ç­›é€‰åçš„å“ç‰Œï¼ˆä»…åŒ…å«é€‰ä¸­çš„èŠ‚ç‚¹ï¼‰
            filtered_brands = []
            
            # ä»ç­›é€‰çš„æºèŠ‚ç‚¹ä¸­æå–å“ç‰Œ
            for node in st.session_state.selected_sources:
                if "æœŸåˆ_" in node:
                    brand = node.split("_", 1)[1]
                    if brand not in ["æ–°å¢é—¨åº—", "æ–°å¢å“ç±»", "é—¨åº—æµå¤±", "å“ç±»æµå¤±", "å…¶ä»–å“ç‰Œ"]:
                        filtered_brands.append(brand)
            
            # ä»ç­›é€‰çš„ç›®æ ‡èŠ‚ç‚¹ä¸­æå–å“ç‰Œ
            for node in st.session_state.selected_targets:
                if "æœŸæœ«_" in node:
                    brand = node.split("_", 1)[1]
                    if brand not in ["æ–°å¢é—¨åº—", "æ–°å¢å“ç±»", "é—¨åº—æµå¤±", "å“ç±»æµå¤±", "å…¶ä»–å“ç‰Œ"] and brand not in filtered_brands:
                        filtered_brands.append(brand)
            
            # ç¡®ä¿æŒ‰èŠ‚ç‚¹é¡ºåºæ’åºï¼ˆæºèŠ‚ç‚¹é¡ºåºä¼˜å…ˆï¼‰
            sorted_brands = []
            # é¦–å…ˆæ·»åŠ æºèŠ‚ç‚¹ä¸­çš„å“ç‰Œï¼ˆæŒ‰æºèŠ‚ç‚¹é¡ºåºï¼‰
            for node in sorted_source_nodes:
                if "æœŸåˆ_" in node:
                    brand = node.split("_", 1)[1]
                    if brand in filtered_brands and brand not in sorted_brands:
                        sorted_brands.append(brand)
            
            # ç„¶åæ·»åŠ ä»…åœ¨ç›®æ ‡èŠ‚ç‚¹ä¸­çš„å“ç‰Œï¼ˆæŒ‰ç›®æ ‡èŠ‚ç‚¹é¡ºåºï¼‰
            for node in sorted_target_nodes:
                if "æœŸæœ«_" in node:
                    brand = node.split("_", 1)[1]
                    if brand in filtered_brands and brand not in sorted_brands:
                        sorted_brands.append(brand)
            
            # ä¸ºæ¯ä¸ªç­›é€‰åçš„å“ç‰Œç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆæŒ‰æ’åºåçš„é¡ºåºï¼‰
            for brand in sorted_brands:
                # 1. å“ç‰ŒAçš„æœŸåˆåˆ†æ
                start_node = f"æœŸåˆ_{brand}"
                if start_node in source_total_flow and start_node in st.session_state.selected_sources:
                    start_total = source_total_flow[start_node] / 10000  # è½¬æ¢ä¸ºä¸‡å•ä½
                    st.write(f"**{brand} æœŸåˆåˆ†æ**")
                    
                    # ç­›é€‰è¯¥å“ç‰Œçš„æ‰€æœ‰æµå‘
                    brand_flows = percentage_df[percentage_df['æºèŠ‚ç‚¹'] == start_node]
                    
                    # ä¿ç•™çš„æ•°æ®
                    retain_flow = 0
                    retain_pct = 0
                    # è½¬æ¢åˆ°å…¶ä»–å“ç‰Œçš„æ•°æ®
                    convert_flows = []
                    # æµå¤±æ•°æ®ï¼ˆç»†åˆ†é—¨åº—æµå¤±å’Œå“ç±»æµå¤±ï¼‰
                    store_loss_flow = 0  # é—¨åº—æµå¤±
                    store_loss_pct = 0
                    category_loss_flow = 0  # å“ç±»æµå¤±
                    category_loss_pct = 0
                    
                    for _, row in brand_flows.iterrows():
                        target = row['ç›®æ ‡èŠ‚ç‚¹']
                        if f"æœŸæœ«_{brand}" == target and target in st.session_state.selected_targets:
                            retain_flow = row['æµé‡(ä¸‡)']
                            retain_pct = row['å æœŸåˆæ¯”(%)']
                        elif "æœŸæœ«_é—¨åº—æµå¤±" == target and target in st.session_state.selected_targets:
                            store_loss_flow = row['æµé‡(ä¸‡)']
                            store_loss_pct = row['å æœŸåˆæ¯”(%)']
                        elif "æœŸæœ«_å“ç±»æµå¤±" == target and target in st.session_state.selected_targets:
                            category_loss_flow = row['æµé‡(ä¸‡)']
                            category_loss_pct = row['å æœŸåˆæ¯”(%)']
                        elif "æœŸæœ«_" in target and target in st.session_state.selected_targets:
                            target_brand = target.split("_", 1)[1]
                            if target_brand != brand:
                                convert_flows.append({
                                    'brand': target_brand,
                                    'flow': row['æµé‡(ä¸‡)'],
                                    'pct': row['å æœŸåˆæ¯”(%)']
                                })
                    
                    # ç”ŸæˆæœŸåˆåˆ†ææ–‡æœ¬
                    report_text = f"{brand}ï¼ŒæœŸåˆé‡‘é¢{start_total:.1f}ä¸‡ï¼Œ"
                    report_text += f"æœŸæœ«ä»æ—§ä½¿ç”¨{brand}çš„é‡‘é¢{retain_flow:.1f}ä¸‡ï¼Œå æ¯”{retain_pct}%ï¼›"
                    
                    # æ·»åŠ è½¬æ¢åˆ°å…¶ä»–å“ç‰Œçš„ä¿¡æ¯
                    for cf in convert_flows[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªä¸»è¦è½¬æ¢
                        report_text += f"è½¬æ¢ä¸º{cf['brand']}çš„é‡‘é¢{cf['flow']:.1f}ä¸‡ï¼Œå æ¯”{cf['pct']}%ï¼›"
                    
                    # æ˜ç¡®åŒºåˆ†é—¨åº—æµå¤±å’Œå“ç±»æµå¤±
                    report_text += f"é—¨åº—æµå¤±é‡‘é¢{store_loss_flow:.1f}ä¸‡ï¼Œå æ¯”{store_loss_pct}%ï¼›"
                    report_text += f"å“ç±»æµå¤±é‡‘é¢{category_loss_flow:.1f}ä¸‡ï¼Œå æ¯”{category_loss_pct}%ï¼›"
                    
                    st.write(report_text)
                
                # 2. å“ç‰ŒAçš„æœŸæœ«åˆ†æ
                end_node = f"æœŸæœ«_{brand}"
                target_total = target_flow_sorted[target_flow_sorted['èŠ‚ç‚¹'] == end_node]['æ€»æµé‡'].values[0] / 10000 if (end_node in target_flow_sorted['èŠ‚ç‚¹'].values and end_node in st.session_state.selected_targets) else 0
                
                if target_total > 0:
                    st.write(f"**{brand} æœŸæœ«åˆ†æ**")
                    
                    # ç­›é€‰æµå‘è¯¥å“ç‰Œçš„æ‰€æœ‰æ¥æº
                    brand_inflows = percentage_df[percentage_df['ç›®æ ‡èŠ‚ç‚¹'] == end_node]
                    
                    # ä¿ç•™çš„æ•°æ®ï¼ˆæ¥è‡ªåŒä¸€å“ç‰Œï¼‰
                    retain_flow = 0
                    retain_pct = 0
                    # ä»å…¶ä»–å“ç‰Œè½¬æ¢æ¥çš„æ•°æ®
                    convert_flows = []
                    # æ–°å¢æ•°æ®ï¼ˆç»†åˆ†æ–°å¢é—¨åº—å’Œæ–°å¢å“ç±»ï¼‰
                    new_store_flow = 0  # æ–°å¢é—¨åº—
                    new_store_pct = 0
                    new_category_flow = 0  # æ–°å¢å“ç±»
                    new_category_pct = 0
                    
                    # è®¡ç®—æ€»æµå…¥é‡
                    total_inflow = brand_inflows['æµé‡(ä¸‡)'].sum()
                    
                    for _, row in brand_inflows.iterrows():
                        source = row['æºèŠ‚ç‚¹']
                        if f"æœŸåˆ_{brand}" == source and source in st.session_state.selected_sources:
                            retain_flow = row['æµé‡(ä¸‡)']
                            retain_pct = row['å æœŸæœ«æ¯”(%)']
                        elif "æœŸåˆ_æ–°å¢é—¨åº—" == source and source in st.session_state.selected_sources:
                            new_store_flow = row['æµé‡(ä¸‡)']
                            new_store_pct = row['å æœŸæœ«æ¯”(%)']
                        elif "æœŸåˆ_æ–°å¢å“ç±»" == source and source in st.session_state.selected_sources:
                            new_category_flow = row['æµé‡(ä¸‡)']
                            new_category_pct = row['å æœŸæœ«æ¯”(%)']
                        elif "æœŸåˆ_" in source and source in st.session_state.selected_sources:
                            source_brand = source.split("_", 1)[1]
                            if source_brand != brand:
                                convert_flows.append({
                                    'brand': source_brand,
                                    'flow': row['æµé‡(ä¸‡)'],
                                    'pct': row['å æœŸæœ«æ¯”(%)']
                                })
                    
                    # ç”ŸæˆæœŸæœ«åˆ†ææ–‡æœ¬
                    report_text = f"{brand}ï¼ŒæœŸæœ«é‡‘é¢{target_total:.1f}ä¸‡ï¼Œ"
                    report_text += f"æ¥è‡ªæœŸåˆ{brand}çš„é‡‘é¢{retain_flow:.1f}ä¸‡ï¼Œå æ¯”{retain_pct:.2f}%ï¼›"
                    
                    # æ·»åŠ ä»å…¶ä»–å“ç‰Œè½¬æ¢æ¥çš„ä¿¡æ¯
                    for cf in convert_flows[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªä¸»è¦æ¥æº
                        report_text += f"ä»{cf['brand']}è½¬æ¢æ¥çš„é‡‘é¢{cf['flow']:.1f}ä¸‡ï¼Œå æ¯”{cf['pct']:.2f}%ï¼›"
                    
                    # æ˜ç¡®åŒºåˆ†æ–°å¢é—¨åº—å’Œæ–°å¢å“ç±»
                    report_text += f"æ–°å¢é—¨åº—é‡‘é¢{new_store_flow:.1f}ä¸‡ï¼Œå æ¯”{new_store_pct:.2f}%ï¼›"
                    report_text += f"æ–°å¢å“ç±»é‡‘é¢{new_category_flow:.1f}ä¸‡ï¼Œå æ¯”{new_category_pct:.2f}%ï¼›"
                    
                    st.write(report_text)
                
                st.write("---")  # åˆ†éš”çº¿
            
            # æä¾›æ•°æ®ä¸‹è½½åŠŸèƒ½
            st.subheader("æ•°æ®ä¸‹è½½ï¼ˆç­›é€‰åï¼‰")
            download_col1, download_col2 = st.columns(2)
            
            with download_col1:
                # æµå‘æ•°æ®ä¸‹è½½ï¼ˆè½¬æ¢ä¸ºä¸‡å•ä½ï¼‰
                flow_for_download = filtered_flow_df.copy()
                flow_for_download['æµé‡'] = flow_for_download['æµé‡'] / 10000
                flow_for_download = flow_for_download.rename(columns={'æµé‡': 'æµé‡(ä¸‡)'})
                flow_csv = flow_for_download.to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½ç­›é€‰åçš„æµå‘æ•°æ®",
                    data=flow_csv,
                    file_name=f"ç­›é€‰å_æ¡‘åŸºå›¾æµå‘æ•°æ®_{st.session_state.start_period}_to_{st.session_state.end_period}.csv",
                    mime="text/csv",
                )
            
            with download_col2:
                # æµé‡å æ¯”æ•°æ®ä¸‹è½½
                percentage_csv = percentage_df.to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½ç­›é€‰åçš„æµé‡å æ¯”æ•°æ®",
                    data=percentage_csv,
                    file_name=f"ç­›é€‰å_æ¡‘åŸºå›¾æµé‡å æ¯”æ•°æ®_{st.session_state.start_period}_to_{st.session_state.end_period}.csv",
                    mime="text/csv",
                )
else:
    st.info("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¼€å§‹åˆ†æï¼ˆæ”¯æŒExcelæ ¼å¼ï¼‰")
