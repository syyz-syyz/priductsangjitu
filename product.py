import streamlit as st
import pandas as pd
import numpy as np
import random
from pyecharts import options as opts
from pyecharts.charts import Sankey
from streamlit_echarts import st_pyecharts
import colorsys

# å®šä¹‰éœ€è¦æ ¡éªŒçš„token
VALID_TOKEN = "mUo2TJ3PC3pqddAmQ3Wq2ZnxnEjAq1yd"
# åˆå§‹åŒ–session_state
if 'flow_df' not in st.session_state:
    st.session_state.flow_df = None
if 'source_nodes' not in st.session_state:
    st.session_state.source_nodes = []
if 'target_nodes' not in st.session_state:
    st.session_state.target_nodes = []
if 'selected_sources' not in st.session_state:
    st.session_state.selected_sources = []
if 'selected_targets' not in st.session_state:
    st.session_state.selected_targets = []
if 'start_period' not in st.session_state:
    st.session_state.start_period = None
if 'end_period' not in st.session_state:
    st.session_state.end_period = None
if 'highlight_keyword' not in st.session_state:
    st.session_state.highlight_keyword = "å®¶ä¹"
if 'show_rank_value' not in st.session_state:
    st.session_state.show_rank_value = True

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å“ç‰Œæµé‡æ¡‘åŸºå›¾åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)


# æ ‡é¢˜
st.title("å“ç‰Œæµé‡æ¡‘åŸºå›¾åˆ†æå·¥å…·")

# å‚æ•°è®¾ç½®åŒºåŸŸ
st.subheader("åˆ†æå‚æ•°è®¾ç½®")
param_col1, param_col2 = st.columns(2)

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
with param_col1:
    uploaded_file = st.file_uploader("è¯·ä¸Šä¼ Excelæ ¼å¼çš„æ•°æ®æ–‡ä»¶ï¼ˆ.xlsxï¼‰", type=["xlsx"])

# å¦‚æœä¸Šä¼ äº†æ–‡ä»¶ï¼Œåˆ™è¿›è¡Œåç»­å‚æ•°è®¾ç½®
if uploaded_file is not None:
    # è¯»å–æ•°æ®ä»¥è·å–Qçš„å¯èƒ½å€¼
    df = pd.read_excel(uploaded_file)
    if 'Q' not in df.columns:
        st.error("ä¸Šä¼ çš„æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„'Q'åˆ—")
        st.stop()
    
    # è·å–Qçš„å”¯ä¸€å€¼å¹¶æ’åº
    q_values = sorted(df['Q'].unique().tolist())
    
    with param_col1:
        # æœŸåˆå’ŒæœŸæœ«é€‰æ‹©
        col1, col2 = st.columns(2)
        with col1:
            start_period = st.selectbox("é€‰æ‹©æœŸåˆ", q_values, index=0)
            st.session_state.start_period = start_period
        with col2:
            end_period = st.selectbox("é€‰æ‹©æœŸæœ«", q_values, index=min(1, len(q_values)-1))
            st.session_state.end_period = end_period
        
        # ç¡®ä¿æœŸåˆä¸ç­‰äºæœŸæœ«
        if start_period == end_period:
            st.error("æœŸåˆå’ŒæœŸæœ«ä¸èƒ½é€‰æ‹©ç›¸åŒçš„å€¼ï¼Œè¯·é‡æ–°é€‰æ‹©")
            st.stop()
    
    with param_col2:
        # å…¶ä»–å‚æ•°è®¾ç½®
        highlight_keyword = st.text_input("èŠ‚ç‚¹é«˜äº®å…³é”®è¯", "å®¶ä¹")
        st.session_state.highlight_keyword = highlight_keyword
        
        top_n_brands = st.slider("ä¿ç•™Top Nå“ç‰Œæ•°é‡", 5, 20, 10)
        
        show_rank_value = st.checkbox("åœ¨èŠ‚ç‚¹æ ‡ç­¾ä¸­æ˜¾ç¤ºæ’åå’Œæ•°å€¼", value=True)
        st.session_state.show_rank_value = show_rank_value
        
        # ç”Ÿæˆæ¡‘åŸºå›¾æŒ‰é’®
        generate_chart = st.button("ç”Ÿæˆæ¡‘åŸºå›¾")
    
    # å½“ç‚¹å‡»ç”ŸæˆæŒ‰é’®æ—¶è¿›è¡Œå¤„ç†
    if generate_chart:
        with st.spinner("æ­£åœ¨è¯»å–å’Œå¤„ç†æ•°æ®..."):
            # ç»Ÿä¸€Value Uåˆ—å
            if 'Value U' not in df.columns and 'Value' in df.columns:
                df = df.rename(columns={'Value': 'Value U'})
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['brand', 'Value U', 'Passport_id', 'Q']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                st.error(f"ä¸Šä¼ çš„æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_columns)}")
                st.stop()
            
            # å¤„ç†å“ç‰Œåˆ—ï¼šèšåˆValue Uå¹¶ä¿ç•™Top Nå“ç‰Œï¼Œç»Ÿä¸€å“ç‰Œåç§°æ ¼å¼
            df['brand_clean'] = df['brand'].str.strip().str.lower()
            brand_values = df.groupby('brand_clean')['Value U'].sum().reset_index()
            brand_values_sorted = brand_values.sort_values('Value U', ascending=False)
            top_brands = brand_values_sorted.head(top_n_brands)['brand_clean'].tolist()
            df['brand_processed'] = df['brand_clean'].apply(lambda x: x if x in top_brands else 'å…¶ä»–å“ç‰Œ')
            
            st.success(f"å·²å¤„ç†å“ç‰Œåˆ—ï¼Œä¿ç•™Top {top_n_brands}å“ç‰Œï¼Œå…¶ä½™å½’ä¸º'å…¶ä»–å“ç‰Œ'")
        
        # è®¡ç®—æµå‘æ•°æ®
        with st.spinner("æ­£åœ¨è®¡ç®—æµå‘æ•°æ®..."):
            flow_results = []
            
            for passport_id, group in df.groupby('Passport_id'):
                has_start = start_period in group['Q'].values
                has_end = end_period in group['Q'].values
                
                # åœºæ™¯1ï¼šåªæœ‰æœŸæœ«
                if not has_start and has_end:
                    brand_data = group[group['Q'] == end_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    for _, row in brand_data.iterrows():
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_æ–°å¢é—¨åº—",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{row['brand_processed']}",
                            'æµé‡': row['Value U']
                        })
                    continue
                
                # åœºæ™¯2ï¼šåªæœ‰æœŸåˆ
                if has_start and not has_end:
                    brand_data = group[group['Q'] == start_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    for _, row in brand_data.iterrows():
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{row['brand_processed']}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_é—¨åº—æµå¤±",
                            'æµé‡': row['Value U']
                        })
                    continue
                
                # åœºæ™¯3ï¼šæ—¢æœ‰æœŸåˆåˆæœ‰æœŸæœ«
                if has_start and has_end:
                    start_data = group[group['Q'] == start_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    end_data = group[group['Q'] == end_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    
                    start_dict = dict(zip(start_data['brand_processed'], start_data['Value U']))
                    end_dict = dict(zip(end_data['brand_processed'], end_data['Value U']))
                    
                    # 1. ç›¸åŒå“ç‰Œä¼˜å…ˆåŒ¹é…
                    common_brands = set(start_dict.keys()) & set(end_dict.keys())
                    remaining_start = start_dict.copy()
                    remaining_end = end_dict.copy()
                    
                    for brand in common_brands:
                        flow = min(start_dict[brand], end_dict[brand])
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand}",
                            'æµé‡': flow
                        })
                        remaining_start[brand] -= flow
                        remaining_end[brand] -= flow
                        if remaining_start[brand] == 0:
                            del remaining_start[brand]
                        if remaining_end[brand] == 0:
                            del remaining_end[brand]
                    
                    # 2. ä¸åŒå“ç‰ŒéšæœºåŒ¹é…å‰©ä½™é‡
                    start_remaining = list(remaining_start.items())
                    end_remaining = list(remaining_end.items())
                    
                    while start_remaining and end_remaining:
                        brand1, val1 = start_remaining[0]
                        brand2, val2 = random.choice(end_remaining)
                        
                        flow = min(val1, val2)
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand1}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand2}",
                            'æµé‡': flow
                        })
                        
                        if val1 == flow:
                            start_remaining.pop(0)
                        else:
                            start_remaining[0] = (brand1, val1 - flow)
                            
                        idx = end_remaining.index((brand2, val2))
                        if val2 == flow:
                            end_remaining.pop(idx)
                        else:
                            end_remaining[idx] = (brand2, val2 - flow)
                    
                    # 3. å¤„ç†æœ€ç»ˆä½™é‡
                    for brand, value in start_remaining:
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_å“ç±»æµå¤±",
                            'æµé‡': value
                        })
                    
                    for brand, value in end_remaining:
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_æ–°å¢å“ç±»",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand}",
                            'æµé‡': value
                        })
            
            st.session_state.flow_df = pd.DataFrame(flow_results, columns=['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹', 'æµé‡'])
            st.success("æµå‘æ•°æ®è®¡ç®—å®Œæˆ")
            
            st.session_state.source_nodes = st.session_state.flow_df['èµ·å§‹ç‚¹'].unique().tolist()
            st.session_state.target_nodes = st.session_state.flow_df['ç›®æ ‡ç‚¹'].unique().tolist()
            
            st.session_state.selected_sources = st.session_state.source_nodes
            st.session_state.selected_targets = st.session_state.target_nodes
    
    if st.session_state.flow_df is not None and not st.session_state.flow_df.empty:
        required_flow_columns = ['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹', 'æµé‡']
        missing_flow_cols = [col for col in required_flow_columns if col not in st.session_state.flow_df.columns]
        if missing_flow_cols:
            st.error(f"æµå‘æ•°æ®ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_flow_cols)}")
            st.stop()
        
        # èŠ‚ç‚¹ç­›é€‰åŒºåŸŸ
        st.subheader("èŠ‚ç‚¹ç­›é€‰")
        filter_col1, filter_col2 = st.columns(2)
        with filter_col1:
            selected_sources = st.multiselect(
                "é€‰æ‹©è¦æ˜¾ç¤ºçš„æœŸåˆèŠ‚ç‚¹",
                st.session_state.source_nodes,
                default=st.session_state.selected_sources
            )
            st.session_state.selected_sources = selected_sources
        with filter_col2:
            selected_targets = st.multiselect(
                "é€‰æ‹©è¦æ˜¾ç¤ºçš„æœŸæœ«èŠ‚ç‚¹",
                st.session_state.target_nodes,
                default=st.session_state.selected_targets
            )
            st.session_state.selected_targets = selected_targets
        
        filtered_flow_df = st.session_state.flow_df[
            st.session_state.flow_df['èµ·å§‹ç‚¹'].isin(st.session_state.selected_sources) & 
            st.session_state.flow_df['ç›®æ ‡ç‚¹'].isin(st.session_state.selected_targets)
        ]
        
        if filtered_flow_df.empty:
            st.warning("ç­›é€‰åæ²¡æœ‰æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
        else:
            with st.spinner("æ­£åœ¨ç”Ÿæˆæ¡‘åŸºå›¾..."):
                aggregated_df = filtered_flow_df.groupby(['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹'], as_index=False)['æµé‡'].sum()
                
                source_nodes_unique = aggregated_df['èµ·å§‹ç‚¹'].unique().tolist()
                target_nodes_unique = aggregated_df['ç›®æ ‡ç‚¹'].unique().tolist()
                
                source_flow = aggregated_df.groupby('èµ·å§‹ç‚¹')['æµé‡'].sum().reset_index()
                source_flow.columns = ['èŠ‚ç‚¹', 'æ€»æµé‡']
                source_flow_sorted = source_flow.sort_values('æ€»æµé‡', ascending=False).reset_index(drop=True)
                sorted_source_nodes = source_flow_sorted['èŠ‚ç‚¹'].tolist()
                
                target_flow = aggregated_df.groupby('ç›®æ ‡ç‚¹')['æµé‡'].sum().reset_index()
                target_flow.columns = ['èŠ‚ç‚¹', 'æ€»æµé‡']
                target_flow_sorted = target_flow.sort_values('æ€»æµé‡', ascending=False).reset_index(drop=True)
                sorted_target_nodes = target_flow_sorted['èŠ‚ç‚¹'].tolist()
                
                all_nodes = sorted_source_nodes + sorted_target_nodes
                node_indices = {node: idx for idx, node in enumerate(all_nodes)}
                
                # ç”ŸæˆèŠ‚ç‚¹é¢œè‰²
                highlight_nodes = [node for node in all_nodes if st.session_state.highlight_keyword in str(node).lower()]
                
                def generate_clear_blue_variations(n):
                    clear_blues = []
                    for i in range(n):
                        hue = 0.58
                        saturation = 0.3 + (i % 3) * 0.1
                        value = 0.9 + (i % 5) * 0.03
                        r, g, b = colorsys.hsv_to_rgb(hue, saturation, value)
                        clear_blues.append(f"rgb({int(r*255)}, {int(g*255)}, {int(b*255)})")
                    return clear_blues
                
                highlight_colors = generate_clear_blue_variations(len(highlight_nodes))
                node_color_map = {node: color for node, color in zip(highlight_nodes, highlight_colors)}
                
                # å‡†å¤‡èŠ‚ç‚¹æ•°æ®
                nodes = []
                node_colors = []
                for i, node in enumerate(all_nodes):
                    if "æœŸåˆ_" in node:
                        node_name = node.replace("æœŸåˆ_", "")
                        if st.session_state.show_rank_value:
                            rank = source_flow_sorted[source_flow_sorted['èŠ‚ç‚¹'] == node].index[0] + 1
                            flow = source_flow_sorted[source_flow_sorted['èŠ‚ç‚¹'] == node]['æ€»æµé‡'].values[0] / 10000
                            label = f"S{rank}. {node_name}\n({flow:.1f}ä¸‡)"
                        else:
                            label = node_name
                    elif "æœŸæœ«_" in node:
                        node_name = node.replace("æœŸæœ«_", "")
                        if st.session_state.show_rank_value:
                            rank = target_flow_sorted[target_flow_sorted['èŠ‚ç‚¹'] == node].index[0] + 1
                            flow = target_flow_sorted[target_flow_sorted['èŠ‚ç‚¹'] == node]['æ€»æµé‡'].values[0] / 10000
                            label = f"T{rank}. {node_name}\n({flow:.1f}ä¸‡)"
                        else:
                            label = node_name
                    else:
                        label = node
                    
                    # è®¾ç½®èŠ‚ç‚¹é¢œè‰²
                    color = node_color_map.get(node, "#dcebff")
                    nodes.append({"name": label})
                    node_colors.append(color)
                
                # å‡†å¤‡é“¾æ¥æ•°æ®
                links = []
                for _, row in aggregated_df.iterrows():
                    source_idx = node_indices[row['èµ·å§‹ç‚¹']]
                    target_idx = node_indices[row['ç›®æ ‡ç‚¹']]
                    value = row['æµé‡']
                    links.append({"source": source_idx, "target": target_idx, "value": value})
                
                # åˆ›å»ºæ¡‘åŸºå›¾
                sankey = (
                    Sankey(init_opts=opts.InitOpts(width="1200px", height="800px"))
                    .add(
                        series_name="",
                        nodes=[{"name": node["name"], "itemStyle": {"color": color}} 
                              for node, color in zip(nodes, node_colors)],
                        links=links,
                        linestyle_opt=opts.LineStyleOpts(opacity=0.7, curve=0.5, color="source"),
                        label_opts=opts.LabelOpts(position="right", font_size=12),
                        node_gap=10,
                        node_width=20,
                    )
                    .set_global_opts(
                        title_opts=opts.TitleOpts(
                            title=f"å“ç‰Œæµé‡æ¡‘åŸºå›¾ï¼ˆ{start_period} â†’ {end_period}ï¼‰- ç­›é€‰å",
                            pos_left="center",
                            title_textstyle_opts=opts.TextStyleOpts(font_size=16),
                        ),
                        tooltip_opts=opts.TooltipOpts(trigger="item", formatter="{b}: {c}"),
                    )
                )
                
                st.success("æ¡‘åŸºå›¾ç”Ÿæˆå®Œæˆ")
            
            try:
                st.subheader(f"å“ç‰Œæµé‡æ¡‘åŸºå›¾ï¼ˆ{st.session_state.start_period} â†’ {st.session_state.end_period}ï¼‰")
                st_pyecharts(sankey, height="800px")
            except Exception as e:
                st.error(f"æ¸²æŸ“æ¡‘åŸºå›¾æ—¶å‡ºé”™: {str(e)}")
                st.write("èŠ‚ç‚¹æ•°é‡:", len(nodes))
                st.write("é“¾æ¥æ•°é‡:", len(links))
                st.write("ç¤ºä¾‹èŠ‚ç‚¹:", nodes[:3])
                st.write("ç¤ºä¾‹é“¾æ¥:", links[:3])
            
            # å…¶ä½™çš„æ•°æ®åˆ†æå’Œä¸‹è½½åŠŸèƒ½ä¿æŒä¸å˜...
            # ...ï¼ˆæ­¤å¤„çœç•¥æµé‡å æ¯”è®¡ç®—å’Œå“ç‰Œåˆ†æéƒ¨åˆ†ä»£ç ï¼‰...

else:
    st.info("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¼€å§‹åˆ†æï¼ˆæ”¯æŒExcelæ ¼å¼ï¼‰")
