import streamlit as st
import pandas as pd
import numpy as np
import random
from pyecharts import options as opts
from pyecharts.charts import Sankey
from streamlit_echarts import st_pyecharts
import colorsys

# åˆå§‹åŒ–session_state
if 'flow_df' not in st.session_state:
    st.session_state.flow_df = None
if 'source_nodes' not in st.session_state:
    st.session_state.source_nodes = []
if 'target_nodes' not in st.session_state:
    st.session_state.target_nodes = []
if 'selected_sources' not in st.session_state:
    st.session_state.selected_sources = []
if 'selected_targets' not in st.session_state:
    st.session_state.selected_targets = []
if 'start_period' not in st.session_state:
    st.session_state.start_period = None
if 'end_period' not in st.session_state:
    st.session_state.end_period = None
if 'highlight_keyword' not in st.session_state:
    st.session_state.highlight_keyword = "å®¶ä¹"
if 'show_rank_value' not in st.session_state:
    st.session_state.show_rank_value = True

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å“ç‰Œæµé‡æ¡‘åŸºå›¾åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"  # ä½¿ç”¨å®½å¸ƒå±€å¢åŠ ç©ºé—´
)


# æ ‡é¢˜
st.title("å“ç‰Œæµé‡æ¡‘åŸºå›¾åˆ†æå·¥å…·")

# å‚æ•°è®¾ç½®åŒºåŸŸ
st.subheader("åˆ†æå‚æ•°è®¾ç½®")
param_col1, param_col2 = st.columns(2)

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
with param_col1:
    uploaded_file = st.file_uploader("è¯·ä¸Šä¼ Excelæ ¼å¼çš„æ•°æ®æ–‡ä»¶ï¼ˆ.xlsxï¼‰", type=["xlsx"])

# å¦‚æœä¸Šä¼ äº†æ–‡ä»¶ï¼Œåˆ™è¿›è¡Œåç»­å‚æ•°è®¾ç½®
if uploaded_file is not None:
    # è¯»å–æ•°æ®ä»¥è·å–Qçš„å¯èƒ½å€¼
    df = pd.read_excel(uploaded_file)
    if 'Q' not in df.columns:
        st.error("ä¸Šä¼ çš„æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„'Q'åˆ—")
        st.stop()
    
    # è·å–Qçš„å”¯ä¸€å€¼å¹¶æ’åº
    q_values = sorted(df['Q'].unique().tolist())
    
    with param_col1:
        # æœŸåˆå’ŒæœŸæœ«é€‰æ‹©
        col1, col2 = st.columns(2)
        with col1:
            start_period = st.selectbox("é€‰æ‹©æœŸåˆ", q_values, index=0)
            st.session_state.start_period = start_period
        with col2:
            end_period = st.selectbox("é€‰æ‹©æœŸæœ«", q_values, index=min(1, len(q_values)-1))
            st.session_state.end_period = end_period
        
        # ç¡®ä¿æœŸåˆä¸ç­‰äºæœŸæœ«
        if start_period == end_period:
            st.error("æœŸåˆå’ŒæœŸæœ«ä¸èƒ½é€‰æ‹©ç›¸åŒçš„å€¼ï¼Œè¯·é‡æ–°é€‰æ‹©")
            st.stop()
    
    with param_col2:
        # å…¶ä»–å‚æ•°è®¾ç½®
        highlight_keyword = st.text_input("èŠ‚ç‚¹é«˜äº®å…³é”®è¯", "å®¶ä¹")
        st.session_state.highlight_keyword = highlight_keyword
        
        top_n_brands = st.slider("ä¿ç•™Top Nå“ç‰Œæ•°é‡", 5, 20, 10)
        
        show_rank_value = st.checkbox("åœ¨èŠ‚ç‚¹æ ‡ç­¾ä¸­æ˜¾ç¤ºæ’åå’Œæ•°å€¼", value=True)
        st.session_state.show_rank_value = show_rank_value
        
        # ç”Ÿæˆæ¡‘åŸºå›¾æŒ‰é’®
        generate_chart = st.button("ç”Ÿæˆæ¡‘åŸºå›¾")
    
    # å½“ç‚¹å‡»ç”ŸæˆæŒ‰é’®æ—¶è¿›è¡Œå¤„ç†
    if generate_chart:
        with st.spinner("æ­£åœ¨è¯»å–å’Œå¤„ç†æ•°æ®..."):
            # ç»Ÿä¸€Value Uåˆ—å
            if 'Value U' not in df.columns and 'Value' in df.columns:
                df = df.rename(columns={'Value': 'Value U'})
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['brand', 'Value U', 'Passport_id', 'Q']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                st.error(f"ä¸Šä¼ çš„æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_columns)}")
                st.stop()
            
            # å¤„ç†å“ç‰Œåˆ—ï¼šèšåˆValue Uå¹¶ä¿ç•™Top Nå“ç‰Œï¼Œç»Ÿä¸€å“ç‰Œåç§°æ ¼å¼
            df['brand_clean'] = df['brand'].str.strip().str.lower()  # æ¸…æ´—å“ç‰Œåç§°
            brand_values = df.groupby('brand_clean')['Value U'].sum().reset_index()
            brand_values_sorted = brand_values.sort_values('Value U', ascending=False)
            top_brands = brand_values_sorted.head(top_n_brands)['brand_clean'].tolist()
            df['brand_processed'] = df['brand_clean'].apply(lambda x: x if x in top_brands else 'å…¶ä»–å“ç‰Œ')
            
            st.success(f"å·²å¤„ç†å“ç‰Œåˆ—ï¼Œä¿ç•™Top {top_n_brands}å“ç‰Œï¼Œå…¶ä½™å½’ä¸º'å…¶ä»–å“ç‰Œ'")
        
        # è®¡ç®—æµå‘æ•°æ®
        with st.spinner("æ­£åœ¨è®¡ç®—æµå‘æ•°æ®..."):
            flow_results = []
            
            # æŒ‰Passport_idåˆ†ç»„å¤„ç†
            for passport_id, group in df.groupby('Passport_id'):
                # æ£€æŸ¥æ˜¯å¦æœ‰æœŸåˆå’ŒæœŸæœ«æ•°æ®
                has_start = start_period in group['Q'].values
                has_end = end_period in group['Q'].values
                
                # åœºæ™¯1ï¼šåªæœ‰æœŸæœ«ï¼ˆæœŸæœ«æœ‰å€¼ï¼ŒæœŸåˆæ— å€¼ï¼‰
                if not has_start and has_end:
                    # æ‰€æœ‰å“ç‰Œéƒ½æ¥è‡ªæœŸåˆ_æ–°å¢é—¨åº—
                    brand_data = group[group['Q'] == end_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    for _, row in brand_data.iterrows():
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_æ–°å¢é—¨åº—",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{row['brand_processed']}",
                            'æµé‡': row['Value U']
                        })
                    continue
                
                # åœºæ™¯2ï¼šåªæœ‰æœŸåˆï¼ˆæœŸåˆæœ‰å€¼ï¼ŒæœŸæœ«æ— å€¼ï¼‰
                if has_start and not has_end:
                    # æ‰€æœ‰å“ç‰Œæµå‘æœŸæœ«_é—¨åº—æµå¤±
                    brand_data = group[group['Q'] == start_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    for _, row in brand_data.iterrows():
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{row['brand_processed']}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_é—¨åº—æµå¤±",
                            'æµé‡': row['Value U']
                        })
                    continue
                
                # åœºæ™¯3ï¼šæ—¢æœ‰æœŸåˆåˆæœ‰æœŸæœ«ï¼ˆå¤„ç†å®Œæ•´æµå‘ï¼‰
                if has_start and has_end:
                    # æŒ‰å“ç‰ŒèšåˆæœŸåˆå’ŒæœŸæœ«çš„æ•°æ®
                    start_data = group[group['Q'] == start_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    end_data = group[group['Q'] == end_period].groupby('brand_processed')['Value U'].sum().reset_index()
                    
                    start_dict = dict(zip(start_data['brand_processed'], start_data['Value U']))
                    end_dict = dict(zip(end_data['brand_processed'], end_data['Value U']))
                    
                    # 1. ç›¸åŒå“ç‰Œä¼˜å…ˆåŒ¹é…
                    common_brands = set(start_dict.keys()) & set(end_dict.keys())
                    remaining_start = start_dict.copy()
                    remaining_end = end_dict.copy()
                    
                    for brand in common_brands:
                        flow = min(start_dict[brand], end_dict[brand])
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand}",
                            'æµé‡': flow
                        })
                        # æ›´æ–°å‰©ä½™é‡
                        remaining_start[brand] -= flow
                        remaining_end[brand] -= flow
                        if remaining_start[brand] == 0:
                            del remaining_start[brand]
                        if remaining_end[brand] == 0:
                            del remaining_end[brand]
                    
                    # 2. ä¸åŒå“ç‰ŒéšæœºåŒ¹é…å‰©ä½™é‡
                    start_remaining = list(remaining_start.items())
                    end_remaining = list(remaining_end.items())
                    
                    while start_remaining and end_remaining:
                        brand1, val1 = start_remaining[0]
                        brand2, val2 = random.choice(end_remaining)
                        
                        flow = min(val1, val2)
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand1}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand2}",
                            'æµé‡': flow
                        })
                        
                        # æ›´æ–°å‰©ä½™é‡
                        if val1 == flow:
                            start_remaining.pop(0)
                        else:
                            start_remaining[0] = (brand1, val1 - flow)
                            
                        idx = end_remaining.index((brand2, val2))
                        if val2 == flow:
                            end_remaining.pop(idx)
                        else:
                            end_remaining[idx] = (brand2, val2 - flow)
                    
                    # 3. å¤„ç†æœ€ç»ˆä½™é‡
                    # æœŸåˆå‰©ä½™é‡æµå‘æœŸæœ«_å“ç±»æµå¤±
                    for brand, value in start_remaining:
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_{brand}",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_å“ç±»æµå¤±",
                            'æµé‡': value
                        })
                    
                    # æœŸæœ«å‰©ä½™é‡æ¥è‡ªæœŸåˆ_æ–°å¢å“ç±»
                    for brand, value in end_remaining:
                        flow_results.append({
                            'èµ·å§‹ç‚¹': f"æœŸåˆ_æ–°å¢å“ç±»",
                            'ç›®æ ‡ç‚¹': f"æœŸæœ«_{brand}",
                            'æµé‡': value
                        })
            
            # ç¡®ä¿flow_dfåŒ…å«æ­£ç¡®çš„åˆ—å
            st.session_state.flow_df = pd.DataFrame(flow_results, columns=['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹', 'æµé‡'])
            st.success("æµå‘æ•°æ®è®¡ç®—å®Œæˆ")
            
            # ä¿å­˜èŠ‚ç‚¹ä¿¡æ¯
            st.session_state.source_nodes = st.session_state.flow_df['èµ·å§‹ç‚¹'].unique().tolist()
            st.session_state.target_nodes = st.session_state.flow_df['ç›®æ ‡ç‚¹'].unique().tolist()
            
            # åˆå§‹åŒ–é€‰æ‹©
            st.session_state.selected_sources = st.session_state.source_nodes
            st.session_state.selected_targets = st.session_state.target_nodes
    
    # åªæœ‰å½“æœ‰æ•°æ®æ—¶æ‰æ˜¾ç¤ºç­›é€‰å’Œå›¾è¡¨
    if st.session_state.flow_df is not None and not st.session_state.flow_df.empty:
        # éªŒè¯å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_flow_columns = ['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹', 'æµé‡']
        missing_flow_cols = [col for col in required_flow_columns if col not in st.session_state.flow_df.columns]
        if missing_flow_cols:
            st.error(f"æµå‘æ•°æ®ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_flow_cols)}")
            st.stop()
        
        # æ·»åŠ èŠ‚ç‚¹ç­›é€‰åŒºåŸŸ
        st.subheader("èŠ‚ç‚¹ç­›é€‰")
        filter_col1, filter_col2 = st.columns(2)
        with filter_col1:
            selected_sources = st.multiselect(
                "é€‰æ‹©è¦æ˜¾ç¤ºçš„æœŸåˆèŠ‚ç‚¹",
                st.session_state.source_nodes,
                default=st.session_state.selected_sources
            )
            st.session_state.selected_sources = selected_sources
        with filter_col2:
            selected_targets = st.multiselect(
                "é€‰æ‹©è¦æ˜¾ç¤ºçš„æœŸæœ«èŠ‚ç‚¹",
                st.session_state.target_nodes,
                default=st.session_state.selected_targets
            )
            st.session_state.selected_targets = selected_targets
        
        # åº”ç”¨ç­›é€‰
        filtered_flow_df = st.session_state.flow_df[
            st.session_state.flow_df['èµ·å§‹ç‚¹'].isin(st.session_state.selected_sources) & 
            st.session_state.flow_df['ç›®æ ‡ç‚¹'].isin(st.session_state.selected_targets)
        ]
        
        # å¦‚æœç­›é€‰åæ²¡æœ‰æ•°æ®
        if filtered_flow_df.empty:
            st.warning("ç­›é€‰åæ²¡æœ‰æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
        else:
            # ç”Ÿæˆæ¡‘åŸºå›¾ï¼ˆåŸºäºç­›é€‰åçš„æ•°æ®ï¼‰
            with st.spinner("æ­£åœ¨ç”Ÿæˆæ¡‘åŸºå›¾..."):
                # ç¡®ä¿èšåˆæ—¶ä½¿ç”¨æ­£ç¡®çš„åˆ—å
                aggregated_df = filtered_flow_df.groupby(['èµ·å§‹ç‚¹', 'ç›®æ ‡ç‚¹'], as_index=False)['æµé‡'].sum()
                
                # åˆ†ç¦»æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹
                source_nodes_unique = aggregated_df['èµ·å§‹ç‚¹'].unique().tolist()
                target_nodes_unique = aggregated_df['ç›®æ ‡ç‚¹'].unique().tolist()
                
                # åˆ†åˆ«æŒ‰æµé‡æ’åº
                # æºèŠ‚ç‚¹æŒ‰æµå‡ºæµé‡æ’åºï¼ˆé™åºï¼‰
                source_flow = aggregated_df.groupby('èµ·å§‹ç‚¹')['æµé‡'].sum().reset_index()
                source_flow.columns = ['èŠ‚ç‚¹', 'æ€»æµé‡']
                source_flow_sorted = source_flow.sort_values('æ€»æµé‡', ascending=False).reset_index(drop=True)
                sorted_source_nodes = source_flow_sorted['èŠ‚ç‚¹'].tolist()
                
                # ç›®æ ‡èŠ‚ç‚¹æŒ‰æµå…¥æµé‡æ’åºï¼ˆé™åºï¼‰
                target_flow = aggregated_df.groupby('ç›®æ ‡ç‚¹')['æµé‡'].sum().reset_index()
                target_flow.columns = ['èŠ‚ç‚¹', 'æ€»æµé‡']
                target_flow_sorted = target_flow.sort_values('æ€»æµé‡', ascending=False).reset_index(drop=True)
                sorted_target_nodes = target_flow_sorted['èŠ‚ç‚¹'].tolist()
                
                # åˆå¹¶èŠ‚ç‚¹åˆ—è¡¨ï¼ˆå·¦ä¾§æºèŠ‚ç‚¹ + å³ä¾§ç›®æ ‡èŠ‚ç‚¹ï¼‰
                all_nodes = sorted_source_nodes + sorted_target_nodes
                
                # åˆ›å»ºèŠ‚ç‚¹ç´¢å¼•æ˜ å°„
                node_indices = {node: idx for idx, node in enumerate(all_nodes)}
                
                # é«˜äº®æŒ‡å®šå…³é”®è¯çš„èŠ‚ç‚¹
                highlight_nodes = [node for node in all_nodes if st.session_state.highlight_keyword in str(node).lower()]
                
                # ç”Ÿæˆæ¸…æ™°çš„è“è‰²ç³»é¢œè‰²å˜åŒ–
                def generate_clear_blue_variations(n):
                    clear_blues = []
                    for i in range(n):
                        hue = 0.58  # è“è‰²è‰²ç›¸
                        saturation = 0.3 + (i % 3) * 0.1  # é€‚ä¸­é¥±å’Œåº¦
                        value = 0.9 + (i % 5) * 0.03  # é«˜æ˜åº¦
                        r, g, b = colorsys.hsv_to_rgb(hue, saturation, value)
                        clear_blues.append(f"rgba({int(r*255)}, {int(g*255)}, {int(b*255)}, 0.8)")  # è½»å¾®é€æ˜
                    return clear_blues
                
                # ç”Ÿæˆæ¸…æ™°çš„è“è‰²ç³»é¢œè‰²
                highlight_colors = generate_clear_blue_variations(len(highlight_nodes))
                node_color_map = {node: color for node, color in zip(highlight_nodes, highlight_colors)}
                
                # å‡†å¤‡èŠ‚ç‚¹æ•°æ®
                nodes = []
                base_clear_blue = "rgba(220, 235, 255, 0.8)"  # åŸºç¡€æµ…è“è‰²
                
                # æºèŠ‚ç‚¹
                for i, node in enumerate(sorted_source_nodes):
                    flow = source_flow_sorted[source_flow_sorted['èŠ‚ç‚¹'] == node]['æ€»æµé‡'].values[0] / 10000
                    node_name = node.replace("æœŸåˆ_", "")
                    if st.session_state.show_rank_value:
                        label = f"S{i+1}. {node_name} ({flow:.1f}ä¸‡)"
                    else:
                        label = f"{node_name}"
                    
                    nodes.append({
                        "name": node,
                        "label": {"show": True, "formatter": label},
                        "itemStyle": {"color": node_color_map.get(node, base_clear_blue)}
                    })
                
                # ç›®æ ‡èŠ‚ç‚¹
                for i, node in enumerate(sorted_target_nodes):
                    flow = target_flow_sorted[target_flow_sorted['èŠ‚ç‚¹'] == node]['æ€»æµé‡'].values[0] / 10000
                    node_name = node.replace("æœŸæœ«_", "")
                    if st.session_state.show_rank_value:
                        label = f"T{i+1}. {node_name} ({flow:.1f}ä¸‡)"
                    else:
                        label = f"{node_name}"
                    
                    nodes.append({
                        "name": node,
                        "label": {"show": True, "formatter": label},
                        "itemStyle": {"color": node_color_map.get(node, base_clear_blue)}
                    })
                
                # å‡†å¤‡é“¾æ¥æ•°æ®
                links = []
                for _, row in aggregated_df.iterrows():
                    src = row['èµ·å§‹ç‚¹']
                    tar = row['ç›®æ ‡ç‚¹']
                    value = row['æµé‡']
                    
                    # ç¡®å®šé“¾æ¥é¢œè‰²
                    if src in node_color_map:
                        link_color = node_color_map[src]
                    elif tar in node_color_map:
                        link_color = node_color_map[tar]
                    else:
                        link_color = "rgba(220, 235, 255, 0.5)"  # éé«˜äº®é“¾æ¥é¢œè‰²
                    
                    links.append({
                        "source": src,
                        "target": tar,
                        "value": value,
                        "lineStyle": {"color": link_color, "opacity": 0.7}
                    })
                
                # åˆ›å»ºæ¡‘åŸºå›¾
                sankey = (
                    Sankey(init_opts=opts.InitOpts(width="1400px", height=f"{max(len(sorted_source_nodes), len(sorted_target_nodes)) * 50 + 200}px"))
                    .add(
                        series_name="",
                        nodes=nodes,
                        links=links,
                        pos_left="15%",
                        pos_right="15%",
                        focus_node_adjacency=True,
                        node_align="justify",
                        layout_iterations=0,  # ç¦ç”¨è‡ªåŠ¨å¸ƒå±€
                        linestyle_opt=opts.LineStyleOpts(opacity=0.3, curve=0.5, color="source"),
                        label_opts=opts.LabelOpts(
                            position="right",
                            font_size=12,
                            font_family="Microsoft YaHei",
                            color="rgb(30, 30, 30)"
                        ),
                        tooltip_opts=opts.TooltipOpts(
                            trigger="item",
                            formatter="""
                            {b}<br/>
                            æµé‡: {c} ({d}%)
                            """
                        ),
                    )
                    .set_global_opts(
                        title_opts=opts.TitleOpts(
                            title=f"å“ç‰Œæµé‡æ¡‘åŸºå›¾ï¼ˆ{start_period} â†’ {end_period}ï¼‰- ç­›é€‰å",
                            pos_left="center",
                            title_textstyle_opts=opts.TextStyleOpts(
                                font_family="Microsoft YaHei",
                                font_size=16,
                                color="rgb(30, 30, 30)"
                            )
                        ),
                        tooltip_opts=opts.TooltipOpts(trigger="item"),
                    )
                )
                
                st.success("æ¡‘åŸºå›¾ç”Ÿæˆå®Œæˆ")
            
            # æ˜¾ç¤ºæ¡‘åŸºå›¾
            st.subheader(f"å“ç‰Œæµé‡æ¡‘åŸºå›¾ï¼ˆ{st.session_state.start_period} â†’ {st.session_state.end_period}ï¼‰")
            st_pyecharts(sankey, height=max(len(sorted_source_nodes), len(sorted_target_nodes)) * 50 + 200)
            
            # è®¡ç®—å¹¶æ˜¾ç¤ºæµé‡å æ¯”æ•°æ®ï¼ˆåŸºäºç­›é€‰åçš„æ•°æ®ï¼‰
            with st.spinner("æ­£åœ¨è®¡ç®—æµé‡å æ¯”æ•°æ®..."):
                # åˆ›å»ºå­—å…¸ç”¨äºå¿«é€ŸæŸ¥æ‰¾æ¯ä¸ªæºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹çš„æ€»æµé‡
                source_total_flow = dict(zip(source_flow['èŠ‚ç‚¹'], source_flow['æ€»æµé‡']))
                target_total_flow = dict(zip(target_flow['èŠ‚ç‚¹'], target_flow['æ€»æµé‡']))
                
                # æŒ‰æºèŠ‚ç‚¹åˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªç›®æ ‡èŠ‚ç‚¹çš„æµé‡å æ¯”
                result = []
                
                # éå†æ¯ä¸ªæºèŠ‚ç‚¹
                for source in sorted_source_nodes:
                    # ç­›é€‰å‡ºè¯¥æºèŠ‚ç‚¹çš„æ‰€æœ‰æµå‡ºæ•°æ®
                    source_data = aggregated_df[aggregated_df['èµ·å§‹ç‚¹'] == source]
                    
                    # è®¡ç®—æ€»æµé‡
                    total_source = source_total_flow[source]
                    
                    # å­˜å‚¨è¯¥æºèŠ‚ç‚¹çš„æ‰€æœ‰æµå‘ä¿¡æ¯
                    flow_info = {
                        'æºèŠ‚ç‚¹': source,
                        'æºèŠ‚ç‚¹æ€»æµé‡': total_source / 10000,  # è½¬æ¢ä¸ºä¸‡å•ä½
                        'æµå‘åˆ†å¸ƒ': []
                    }
                    
                    # éå†æ¯ä¸ªç›®æ ‡èŠ‚ç‚¹ï¼Œè®¡ç®—å æ¯”
                    for _, row in source_data.iterrows():
                        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åˆ—å
                        target = row['ç›®æ ‡ç‚¹']
                        flow = row['æµé‡']
                        total_target = target_total_flow[target]
                        
                        # è®¡ç®—å æ¯”ï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
                        pct_source = round((flow / total_source) * 100, 2)  # å æœŸåˆæ¯”
                        pct_target = round((flow / total_target) * 100, 2)  # å æœŸæœ«æ¯”
                        
                        flow_info['æµå‘åˆ†å¸ƒ'].append({
                            'ç›®æ ‡èŠ‚ç‚¹': target,
                            'æµé‡': flow / 10000,  # è½¬æ¢ä¸ºä¸‡å•ä½
                            'å æœŸåˆæ¯”(%)': pct_source,
                            'å æœŸæœ«æ¯”(%)': pct_target
                        })
                    
                    # æŒ‰å æ¯”é™åºæ’åº
                    flow_info['æµå‘åˆ†å¸ƒ'].sort(key=lambda x: x['å æœŸåˆæ¯”(%)'], reverse=True)
                    result.append(flow_info)
                
                # è½¬æ¢ä¸ºDataFrameä»¥ä¾¿æ›´å¥½åœ°æŸ¥çœ‹
                rows = []
                for item in result:
                    for flow in item['æµå‘åˆ†å¸ƒ']:
                        rows.append({
                            'æºèŠ‚ç‚¹': item['æºèŠ‚ç‚¹'],
                            'æºèŠ‚ç‚¹æ€»æµé‡(ä¸‡)': item['æºèŠ‚ç‚¹æ€»æµé‡'],
                            'ç›®æ ‡èŠ‚ç‚¹': flow['ç›®æ ‡èŠ‚ç‚¹'],
                            'æµé‡(ä¸‡)': flow['æµé‡'],
                            'å æœŸåˆæ¯”(%)': flow['å æœŸåˆæ¯”(%)'],
                            'å æœŸæœ«æ¯”(%)': flow['å æœŸæœ«æ¯”(%)']
                        })
                
                percentage_df = pd.DataFrame(rows)
                st.success("æµé‡å æ¯”æ•°æ®è®¡ç®—å®Œæˆ")
            
            # æ˜¾ç¤ºæµé‡å æ¯”æ•°æ®ï¼ˆä¸»è¦è¾“å‡ºï¼‰
            st.subheader("æµé‡å æ¯”è¯¦ç»†æ•°æ®ï¼ˆç­›é€‰åï¼‰")
            st.dataframe(percentage_df)
            
            # ç”Ÿæˆå“ç‰Œåˆ†ææŠ¥å‘Š
            st.subheader("å“ç‰Œæµé‡åˆ†ææŠ¥å‘Š")
            
            # æå–ç­›é€‰åçš„å“ç‰Œï¼ˆä»…åŒ…å«é€‰ä¸­çš„èŠ‚ç‚¹ï¼‰
            filtered_brands = []
            
            # ä»ç­›é€‰çš„æºèŠ‚ç‚¹ä¸­æå–å“ç‰Œ
            for node in st.session_state.selected_sources:
                if "æœŸåˆ_" in node:
                    brand = node.split("_", 1)[1]
                    if brand not in ["æ–°å¢é—¨åº—", "æ–°å¢å“ç±»", "é—¨åº—æµå¤±", "å“ç±»æµå¤±", "å…¶ä»–å“ç‰Œ"]:
                        filtered_brands.append(brand)
            
            # ä»ç­›é€‰çš„ç›®æ ‡èŠ‚ç‚¹ä¸­æå–å“ç‰Œ
            for node in st.session_state.selected_targets:
                if "æœŸæœ«_" in node:
                    brand = node.split("_", 1)[1]
                    if brand not in ["æ–°å¢é—¨åº—", "æ–°å¢å“ç±»", "é—¨åº—æµå¤±", "å“ç±»æµå¤±", "å…¶ä»–å“ç‰Œ"] and brand not in filtered_brands:
                        filtered_brands.append(brand)
            
            # ç¡®ä¿æŒ‰èŠ‚ç‚¹é¡ºåºæ’åºï¼ˆæºèŠ‚ç‚¹é¡ºåºä¼˜å…ˆï¼‰
            sorted_brands = []
            # é¦–å…ˆæ·»åŠ æºèŠ‚ç‚¹ä¸­çš„å“ç‰Œï¼ˆæŒ‰æºèŠ‚ç‚¹é¡ºåºï¼‰
            for node in sorted_source_nodes:
                if "æœŸåˆ_" in node:
                    brand = node.split("_", 1)[1]
                    if brand in filtered_brands and brand not in sorted_brands:
                        sorted_brands.append(brand)
            
            # ç„¶åæ·»åŠ ä»…åœ¨ç›®æ ‡èŠ‚ç‚¹ä¸­çš„å“ç‰Œï¼ˆæŒ‰ç›®æ ‡èŠ‚ç‚¹é¡ºåºï¼‰
            for node in sorted_target_nodes:
                if "æœŸæœ«_" in node:
                    brand = node.split("_", 1)[1]
                    if brand in filtered_brands and brand not in sorted_brands:
                        sorted_brands.append(brand)
            
            # ä¸ºæ¯ä¸ªç­›é€‰åçš„å“ç‰Œç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆæŒ‰æ’åºåçš„é¡ºåºï¼‰
            for brand in sorted_brands:
                # 1. å“ç‰ŒAçš„æœŸåˆåˆ†æ
                start_node = f"æœŸåˆ_{brand}"
                if start_node in source_total_flow and start_node in st.session_state.selected_sources:
                    start_total = source_total_flow[start_node] / 10000  # è½¬æ¢ä¸ºä¸‡å•ä½
                    st.write(f"**{brand} æœŸåˆåˆ†æ**")
                    
                    # ç­›é€‰è¯¥å“ç‰Œçš„æ‰€æœ‰æµå‘
                    brand_flows = percentage_df[percentage_df['æºèŠ‚ç‚¹'] == start_node]
                    
                    # ä¿ç•™çš„æ•°æ®
                    retain_flow = 0
                    retain_pct = 0
                    # è½¬æ¢åˆ°å…¶ä»–å“ç‰Œçš„æ•°æ®
                    convert_flows = []
                    # æµå¤±æ•°æ®ï¼ˆç»†åˆ†é—¨åº—æµå¤±å’Œå“ç±»æµå¤±ï¼‰
                    store_loss_flow = 0  # é—¨åº—æµå¤±
                    store_loss_pct = 0
                    category_loss_flow = 0  # å“ç±»æµå¤±
                    category_loss_pct = 0
                    
                    for _, row in brand_flows.iterrows():
                        target = row['ç›®æ ‡èŠ‚ç‚¹']
                        if f"æœŸæœ«_{brand}" == target and target in st.session_state.selected_targets:
                            retain_flow = row['æµé‡(ä¸‡)']
                            retain_pct = row['å æœŸåˆæ¯”(%)']
                        elif "æœŸæœ«_é—¨åº—æµå¤±" == target and target in st.session_state.selected_targets:
                            store_loss_flow = row['æµé‡(ä¸‡)']
                            store_loss_pct = row['å æœŸåˆæ¯”(%)']
                        elif "æœŸæœ«_å“ç±»æµå¤±" == target and target in st.session_state.selected_targets:
                            category_loss_flow = row['æµé‡(ä¸‡)']
                            category_loss_pct = row['å æœŸåˆæ¯”(%)']
                        elif "æœŸæœ«_" in target and target in st.session_state.selected_targets:
                            target_brand = target.split("_", 1)[1]
                            if target_brand != brand:
                                convert_flows.append({
                                    'brand': target_brand,
                                    'flow': row['æµé‡(ä¸‡)'],
                                    'pct': row['å æœŸåˆæ¯”(%)']
                                })
                    
                    # ç”ŸæˆæœŸåˆåˆ†ææ–‡æœ¬
                    report_text = f"{brand}ï¼ŒæœŸåˆé‡‘é¢{start_total:.1f}ä¸‡ï¼Œ"
                    report_text += f"æœŸæœ«ä»æ—§ä½¿ç”¨{brand}çš„é‡‘é¢{retain_flow:.1f}ä¸‡ï¼Œå æ¯”{retain_pct}%ï¼›"
                    
                    # æ·»åŠ è½¬æ¢åˆ°å…¶ä»–å“ç‰Œçš„ä¿¡æ¯
                    for cf in convert_flows[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªä¸»è¦è½¬æ¢
                        report_text += f"è½¬æ¢ä¸º{cf['brand']}çš„é‡‘é¢{cf['flow']:.1f}ä¸‡ï¼Œå æ¯”{cf['pct']}%ï¼›"
                    
                    # æ˜ç¡®åŒºåˆ†é—¨åº—æµå¤±å’Œå“ç±»æµå¤±
                    report_text += f"é—¨åº—æµå¤±é‡‘é¢{store_loss_flow:.1f}ä¸‡ï¼Œå æ¯”{store_loss_pct}%ï¼›"
                    report_text += f"å“ç±»æµå¤±é‡‘é¢{category_loss_flow:.1f}ä¸‡ï¼Œå æ¯”{category_loss_pct}%ï¼›"
                    
                    st.write(report_text)
                
                # 2. å“ç‰ŒAçš„æœŸæœ«åˆ†æ
                end_node = f"æœŸæœ«_{brand}"
                target_total = target_flow_sorted[target_flow_sorted['èŠ‚ç‚¹'] == end_node]['æ€»æµé‡'].values[0] / 10000 if (end_node in target_flow_sorted['èŠ‚ç‚¹'].values and end_node in st.session_state.selected_targets) else 0
                
                if target_total > 0:
                    st.write(f"**{brand} æœŸæœ«åˆ†æ**")
                    
                    # ç­›é€‰æµå‘è¯¥å“ç‰Œçš„æ‰€æœ‰æ¥æº
                    brand_inflows = percentage_df[percentage_df['ç›®æ ‡èŠ‚ç‚¹'] == end_node]
                    
                    # ä¿ç•™çš„æ•°æ®ï¼ˆæ¥è‡ªåŒä¸€å“ç‰Œï¼‰
                    retain_flow = 0
                    retain_pct = 0
                    # ä»å…¶ä»–å“ç‰Œè½¬æ¢æ¥çš„æ•°æ®
                    convert_flows = []
                    # æ–°å¢æ•°æ®ï¼ˆç»†åˆ†æ–°å¢é—¨åº—å’Œæ–°å¢å“ç±»ï¼‰
                    new_store_flow = 0  # æ–°å¢é—¨åº—
                    new_store_pct = 0
                    new_category_flow = 0  # æ–°å¢å“ç±»
                    new_category_pct = 0
                    
                    # è®¡ç®—æ€»æµå…¥é‡
                    total_inflow = brand_inflows['æµé‡(ä¸‡)'].sum()
                    
                    for _, row in brand_inflows.iterrows():
                        source = row['æºèŠ‚ç‚¹']
                        if f"æœŸåˆ_{brand}" == source and source in st.session_state.selected_sources:
                            retain_flow = row['æµé‡(ä¸‡)']
                            retain_pct = row['å æœŸæœ«æ¯”(%)']
                        elif "æœŸåˆ_æ–°å¢é—¨åº—" == source and source in st.session_state.selected_sources:
                            new_store_flow = row['æµé‡(ä¸‡)']
                            new_store_pct = row['å æœŸæœ«æ¯”(%)']
                        elif "æœŸåˆ_æ–°å¢å“ç±»" == source and source in st.session_state.selected_sources:
                            new_category_flow = row['æµé‡(ä¸‡)']
                            new_category_pct = row['å æœŸæœ«æ¯”(%)']
                        elif "æœŸåˆ_" in source and source in st.session_state.selected_sources:
                            source_brand = source.split("_", 1)[1]
                            if source_brand != brand:
                                convert_flows.append({
                                    'brand': source_brand,
                                    'flow': row['æµé‡(ä¸‡)'],
                                    'pct': row['å æœŸæœ«æ¯”(%)']
                                })
                    
                    # ç”ŸæˆæœŸæœ«åˆ†ææ–‡æœ¬
                    report_text = f"{brand}ï¼ŒæœŸæœ«é‡‘é¢{target_total:.1f}ä¸‡ï¼Œ"
                    report_text += f"æ¥è‡ªæœŸåˆ{brand}çš„é‡‘é¢{retain_flow:.1f}ä¸‡ï¼Œå æ¯”{retain_pct:.2f}%ï¼›"
                    
                    # æ·»åŠ ä»å…¶ä»–å“ç‰Œè½¬æ¢æ¥çš„ä¿¡æ¯
                    for cf in convert_flows[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªä¸»è¦æ¥æº
                        report_text += f"ä»{cf['brand']}è½¬æ¢æ¥çš„é‡‘é¢{cf['flow']:.1f}ä¸‡ï¼Œå æ¯”{cf['pct']:.2f}%ï¼›"
                    
                    # æ˜ç¡®åŒºåˆ†æ–°å¢é—¨åº—å’Œæ–°å¢å“ç±»
                    report_text += f"æ–°å¢é—¨åº—é‡‘é¢{new_store_flow:.1f}ä¸‡ï¼Œå æ¯”{new_store_pct:.2f}%ï¼›"
                    report_text += f"æ–°å¢å“ç±»é‡‘é¢{new_category_flow:.1f}ä¸‡ï¼Œå æ¯”{new_category_pct:.2f}%ï¼›"
                    
                    st.write(report_text)
                
                st.write("---")  # åˆ†éš”çº¿
            
            # æä¾›æ•°æ®ä¸‹è½½åŠŸèƒ½
            st.subheader("æ•°æ®ä¸‹è½½ï¼ˆç­›é€‰åï¼‰")
            download_col1, download_col2 = st.columns(2)
            
            with download_col1:
                # æµå‘æ•°æ®ä¸‹è½½ï¼ˆè½¬æ¢ä¸ºä¸‡å•ä½ï¼‰
                flow_for_download = filtered_flow_df.copy()
                flow_for_download['æµé‡'] = flow_for_download['æµé‡'] / 10000
                flow_for_download = flow_for_download.rename(columns={'æµé‡': 'æµé‡(ä¸‡)'})
                flow_csv = flow_for_download.to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½ç­›é€‰åçš„æµå‘æ•°æ®",
                    data=flow_csv,
                    file_name=f"ç­›é€‰å_æ¡‘åŸºå›¾æµå‘æ•°æ®_{st.session_state.start_period}_to_{st.session_state.end_period}.csv",
                    mime="text/csv",
                )
            
            with download_col2:
                # æµé‡å æ¯”æ•°æ®ä¸‹è½½
                percentage_csv = percentage_df.to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½ç­›é€‰åçš„æµé‡å æ¯”æ•°æ®",
                    data=percentage_csv,
                    file_name=f"ç­›é€‰å_æ¡‘åŸºå›¾æµé‡å æ¯”æ•°æ®_{st.session_state.start_period}_to_{st.session_state.end_period}.csv",
                    mime="text/csv",
                )
else:
    st.info("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¼€å§‹åˆ†æï¼ˆæ”¯æŒExcelæ ¼å¼ï¼‰")
